{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing stuff to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author(s): Mike Talbot, Laura Stock-Caldwell  \n",
    "Date Created: 12/12/18\n",
    "\n",
    "Written Stuff:  \n",
    "This is to test out the NLTK (Natural Language ToolKit)\n",
    "\n",
    "EDIT LOG:  \n",
    "12/12/18: Now it exists\n",
    "31/01/2019: re expressions added and used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Do this once when you fisrt install :) \n",
    "#nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "['201', '00a9', 'abl', 'abov', 'abrupt', 'abstract', 'academ', 'accept', 'account', 'across', 'act', 'adjust', 'advanc', 'affect', 'allow', 'almost', 'alon', 'also', 'although', 'analy', 'anoth', 'appear', 'area', 'around', 'articl', 'asign', 'aspect', 'assist', 'author', 'author', 'avail', 'background', 'based', 'basic', 'befor', 'best', 'better', 'beyond', 'bias', 'bring', 'came', 'candid', 'central', 'certain', 'chapter', 'claim', 'clear', 'close', 'collabor', 'come', 'compar', 'concept', 'conclu', 'consid', 'control', 'could', 'critic', 'critiqu', 'data', 'degree', 'demonstr', 'develop', 'diff', 'discuss', 'draw', 'easil', 'effect', 'elsevi', 'ensur', 'enter', 'equal', 'examin', 'exampl', 'exclud', 'experim', 'expla', 'explor', 'factor', 'figur', 'findings', 'focus', 'found', 'four', 'func', 'fundament', 'furthermor', 'futur', 'get', 'given', 'good', 'grant', 'great', 'group', 'half', 'held', 'idea', 'ident', 'immedi', 'includ', 'increas', 'increas', 'inform', 'investigat', 'inspir', 'item', 'john', 'lack', 'layer', 'like', 'low', 'main', 'major', 'manner', 'match', 'may', 'measur', 'meet', 'method', 'month', 'much', 'must', 'observ', 'otherwis', 'outcom', 'overal', 'paper', 'part', 'perform', 'peter', 'plu', 'pos', 'positiv', 'present', 'previous', 'prim', 'problem', 'process', 'project', 'promis', 'proof', 'propos', 'provid', 'publish', 'purpos', 'reason', 'recent', 'record', 'reduce', 'reliabl', 'report', 'represent', 'requir', 'research', 'reserv', 'resolv', 'result', 'review', 'sampl', 'say', 'scienc', 'secondari', 'see', 'seek', 'seem', 'seen', 'setup', 'share', 'show', 'similar', 'slow', 'small', 'smaller', 'solut', 'someon', 'sometim', 'start', 'stay', 'step', 'still', 'strict', 'studi', 'subject', 'support', 'sure', 'sustain', 'system', 'take', 'technique', 'ten', 'tend', 'term', 'test', 'text', 'therefor', 'thing', 'think', 'thousand', 'three', 'throughout', 'thus', 'tim', 'time', 'top', 'total', 'toward', 'trend', 'truli', 'two', 'ultim', 'under', 'upon', 'upper', 'urgenc', 'urgent', 'use', 'using', 'usual', 'valid', 'variat', 'vs', 'want', 'way', 'welcom', 'whenev', 'wherea', 'wherebi', 'whether', 'whethher', 'whilst', 'whole', 'whose', 'wide', 'with', 'within', 'work', 'would', 'year', 'yet']\n"
     ]
    }
   ],
   "source": [
    "Stop_Words = stopwords.words('english')\n",
    "print(Stop_Words)\n",
    "New_Stop_Words = pandas.read_csv('stopwords_research.csv')\n",
    "Partial_Stop_Words = list(New_Stop_Words['words'])\n",
    "print(Partial_Stop_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Articles = pandas.read_csv('articlesSmall.csv')\n",
    "Abstracts = Articles['Abstract']\n",
    "#Abstracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this paper explores a proof of concept self-centring spinal column concept experimentally. the idea of the system is inspired by the mechanical interaction of the vertebral bones and intervertebral discs in human spine. experimental tests are undertaken to explore whether a similar bridge pier system could be constructed to withstand seismic dynamic loading in an equally efficient manner. the experimentation is performed on tied (pre-tensioned) wooden blocks (vertebrae) with and without rubber strips between the vertebrae acting as the intervertebral discs. small-scale test specimens are excited sinusoidally using a small-scale shake table, and the response of the system recorded through triaxial accelerometers attached to the structure. the nonlinear dynamic response and mechanics of the system are then investigated under sinusoidal dynamic excitation. it is found that the integration of intervertebral rubber discs into wooden vertebrae reduces the nonlinearity of the system, and increases the flexibility and damping. the experimental results show that the proposed system can sustain large lateral displacement without any residual deformation after the excitation. Â© 2018 the authors\n"
     ]
    }
   ],
   "source": [
    "Line = Abstracts[0]\n",
    "line = Line.lower()\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "47\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "Num_Stop_Words  = 0\n",
    "for word in Stop_Words:\n",
    "    word = r'\\b'+word+r'\\b'\n",
    "    matches = re.findall(word,line)   \n",
    "    Num_Stop_Words = Num_Stop_Words + len(matches)\n",
    "    line = re.sub(r'[^\\w\\s]','',line)\n",
    "print(Num_Stop_Words)\n",
    "Num_Tech_Stop_Words = 0\n",
    "for word in Partial_Stop_Words:\n",
    "    word = r'\\b'+ word +r'\\w*.?,?\\s'\n",
    "    matches = re.findall(word,line) \n",
    "    Num_Tech_Stop_Words = Num_Tech_Stop_Words + len(matches)\n",
    "print(Num_Tech_Stop_Words)\n",
    "text = line.split()\n",
    "Len_Abs = len(text)\n",
    "print(Len_Abs)\n",
    "Perc_Keywords = Len_Abs - Num_Tech_Stop_Words - Num_Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of normal human words for a abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'system', 'a', 'are', 'discs', 'dynamic', 'intervertebral', 'is']\n"
     ]
    }
   ],
   "source": [
    "text = line.split()\n",
    "text.sort()\n",
    "\n",
    "#print(text) \n",
    "Word_List = []\n",
    "Count_List = []\n",
    "for word in text:\n",
    "    if Word_List.count(word) == 0:\n",
    "        Word_List.append(word)\n",
    "        Count_List.append(1)\n",
    "    else:\n",
    "        ind = Word_List.index(word)\n",
    "        Count_List[ind] = Count_List[ind]+1\n",
    "#print(Word_List)\n",
    "#print(Count_List)\n",
    "#Find words that occur the most\n",
    "NumWords = len(Word_List)//10\n",
    "Keywords = []\n",
    "for i in range(NumWords):\n",
    "    Max = max(Count_List)\n",
    "    ind = Count_List.index(Max)\n",
    "    Keywords.append(Word_List.pop(ind))\n",
    "    Count_List.remove(Max)\n",
    "print(Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# Find articles to compare for specific collaborations (most and least successful)\n",
    "# Get information of each word\n",
    "# Compare between group of abstracts to find the most common words\n",
    "# Is there a difference in the words used between the successful and unsuccessful?\n",
    "# Can we make a binary recommendation system to predict whether an article will be successful or not based on the words in the abstract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
